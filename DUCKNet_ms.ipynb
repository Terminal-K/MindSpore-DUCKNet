{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6739919f-c36a-4c76-aaff-7aa5a5b7511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip kvasir-seg.zip -d ./\n",
    "!mv Kvasir-SEG/ kvasir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcef2a75-13f2-4b7d-a1c8-3f10803636c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled scipy-1.5.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mindvision 0.1.0 requires scikit-learn>=0.23.1, but you have scikit-learn 0.22.1 which is incompatible.\n",
      "mindinsight 1.7.0 requires pyyaml>=5.3.1, but you have pyyaml 5.1 which is incompatible.\n",
      "mindinsight 1.7.0 requires scikit-learn>=0.23.1, but you have scikit-learn 0.22.1 which is incompatible.\u001b[0m\n",
      "Successfully installed astunparse-1.6.3 mindspore-2.2.0 scipy-1.7.3\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/home/ma-user/anaconda3/envs/MindSpore/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall mindspore-gpu -y\n",
    "!pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/2.2.0/MindSpore/unified/x86_64/mindspore-2.2.0-cp37-cp37m-linux_x86_64.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6133a4a8-f684-4ef3-83e6-14096451dfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MindSpore version:  2.2.0\n",
      "The result of multiplication calculation is correct, MindSpore has been installed on platform [GPU] successfully!\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import mindspore;mindspore.set_context(device_target='GPU');mindspore.run_check()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b463953f-e44b-4ad0-aa5e-2ff13ec0d33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "\n",
    "from sklearn.metrics import jaccard_score, precision_score, recall_score, accuracy_score, f1_score\n",
    "from ModelArchitecture.DUCK_NET_MS import DuckNet\n",
    "from ModelArchitecture.Matrix import PixelAccuracy, IntersectionOverUnion, Recall, Precision\n",
    "from ImageLoader.ImageDataset_ms import get_whole_dataset, create_dataset\n",
    "\n",
    "img_size = 352\n",
    "num_class = 1\n",
    "seed_value = 58800\n",
    "batch_size = 8\n",
    "folder_path = \"./kvasir/\"  # Add the path to your data directory\n",
    "\n",
    "dataset_type = 'kvasir' # Options: kvasir/cvc-clinicdb/cvc-colondb/etis-laribpolypdb\n",
    "learning_rate = 1e-4\n",
    "filters = 17 # Number of filters, the paper presents the results with 17 and 34\n",
    "EPOCHS = 600\n",
    "min_loss_for_saving = 0.2\n",
    "\n",
    "print(\"import complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70bbc6b-d0a9-4eff-bc18-4954ef546922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing training images and masks: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:21, 47.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据量： 800\n",
      "验证集数据量： 100\n",
      "验证集数据量： 100\n",
      "The dataset has been completed!\n"
     ]
    }
   ],
   "source": [
    "ct = datetime.now()\n",
    "model_type = \"DuckNet\"\n",
    "progress_root = \"./ProgressFull/\"\n",
    "best_ckpt_dir = \"./BestCheckpoint\"  # 最佳模型保存路径\n",
    "if not os.path.exists(best_ckpt_dir): os.mkdir(best_ckpt_dir)\n",
    "progressfull_path = progress_root + dataset_type + '_progress_' + model_type + '_filters_' + str(filters) + '_' + str(ct)\n",
    "if not os.path.exists(progressfull_path): os.makedirs(progressfull_path)\n",
    "\n",
    "split_folder_path = get_whole_dataset(folder_path=folder_path, img_size=img_size, seed_value=seed_value)\n",
    "train_dataset = create_dataset(split_folder_path[\"train\"], batch_size=batch_size, augment=True, shuffle=True, seed_value=seed_value)\n",
    "step_size_train = train_dataset.get_dataset_size()\n",
    "val_dataset = create_dataset(split_folder_path[\"val\"], batch_size=batch_size, augment=False, shuffle=False, seed_value=seed_value)\n",
    "test_dataset = create_dataset(split_folder_path[\"test\"], batch_size=batch_size, augment=False, shuffle=False, seed_value=seed_value)\n",
    "\n",
    "print(\"The dataset has been completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537fb9f0-a969-40cf-9f89-f340b5a1a83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been generated!\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "network = DuckNet(img_height=img_size, img_width=img_size, input_chanels=3, out_classes=num_class, starting_filters=filters)\n",
    "optimizer = nn.RMSProp(params=network.trainable_params(), learning_rate=learning_rate)\n",
    "loss_fn = nn.DiceLoss()\n",
    "model = ms.train.Model(network, loss_fn, optimizer, metrics={\"pixel accuracy\": PixelAccuracy(num_class=num_class),\n",
    "                                                             \"IoU\": IntersectionOverUnion(num_class=num_class),\n",
    "                                                             \"recall\": Recall(num_class=num_class),\n",
    "                                                             \"precision\": Precision(num_class=num_class)})\n",
    "print(\"The model has been generated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec848004-5ff4-474c-ae5c-4845dbe2cc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training tools are ready!\n"
     ]
    }
   ],
   "source": [
    "train_acc_tool = PixelAccuracy(num_class=num_class)\n",
    "train_iou_tool = IntersectionOverUnion(num_class=num_class)\n",
    "train_recall_tool = Recall(num_class=num_class)\n",
    "train_precision_tool = Precision(num_class=num_class)\n",
    "\n",
    "def forward_fn(inputs, targets):\n",
    "    logits = network(inputs)\n",
    "    # pred = np.where(logits.asnumpy() > 0.5, 1., 0.)\n",
    "    pred = ms.numpy.where(logits > 0.5, 1., 0.)\n",
    "    train_acc_tool.update(pred, targets)\n",
    "    train_iou_tool.update(pred, targets)\n",
    "    train_recall_tool.update(pred, targets)\n",
    "    train_precision_tool.update(pred, targets)\n",
    "\n",
    "    loss = loss_fn(logits, targets)\n",
    "\n",
    "    return loss\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "def train_step(inputs, targets):\n",
    "    loss, grads = grad_fn(inputs, targets)\n",
    "    optimizer(grads)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 创建迭代器\n",
    "data_loader_train = train_dataset.create_tuple_iterator(num_epochs=EPOCHS)\n",
    "\n",
    "print(\"The training tools are ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bba5083-93ca-4ee9-8c32-076ff1eaff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training Loop ...\n",
      "--------------------\n",
      "Epoch: [  1/600], Average Train Loss: [0.654] | Train pixel Acc: [0.462] | Train IoU: [0.119] | Train R: [0.465] | Train P: [0.140] | Val pixel Acc: [0.453] | Val IoU: [0.136] | Val R: [0.796] | Val P: [0.141] \n",
      "epoch time: 151.702 s, per step time: 1.517 s\n",
      "*************************************************\n",
      "The best IoU achieved so far is: [0.136], the weight has been saved\n",
      "*************************************************\n",
      "Test Acc: [0.472] | Test IoU: [0.176] | Test R: [0.785] | Test P: [0.187]\n",
      "--------------------\n",
      "Epoch: [  2/600], Average Train Loss: [0.527] | Train pixel Acc: [0.655] | Train IoU: [0.276] | Train R: [0.830] | Train P: [0.295] | Val pixel Acc: [0.644] | Val IoU: [0.193] | Val R: [0.800] | Val P: [0.207] \n",
      "epoch time: 137.944 s, per step time: 1.379 s\n",
      "*************************************************\n",
      "The best IoU achieved so far is: [0.193], the weight has been saved\n",
      "*************************************************\n",
      "Test Acc: [0.684] | Test IoU: [0.246] | Test R: [0.729] | Test P: [0.277]\n",
      "--------------------\n",
      "Epoch: [  3/600], Average Train Loss: [0.465] | Train pixel Acc: [0.750] | Train IoU: [0.334] | Train R: [0.806] | Train P: [0.370] | Val pixel Acc: [0.687] | Val IoU: [0.229] | Val R: [0.854] | Val P: [0.241] \n",
      "epoch time: 137.693 s, per step time: 1.377 s\n",
      "*************************************************\n",
      "The best IoU achieved so far is: [0.229], the weight has been saved\n",
      "*************************************************\n",
      "Test Acc: [0.727] | Test IoU: [0.285] | Test R: [0.772] | Test P: [0.315]\n"
     ]
    }
   ],
   "source": [
    "# 开始循环训练\n",
    "print(\"Start Training Loop ...\")\n",
    "\n",
    "best_iou = 0\n",
    "\n",
    "with ms.SummaryRecord(os.path.join(progressfull_path, \"summary\"), network=network) as summary_record:\n",
    "    for epoch in range(EPOCHS):\n",
    "        losses = []\n",
    "        network.set_train()\n",
    "\n",
    "        epoch_start = time.time()\n",
    "\n",
    "        train_acc_tool.clear()\n",
    "        train_iou_tool.clear()\n",
    "        train_recall_tool.clear()\n",
    "        train_precision_tool.clear()\n",
    "        # 为每轮训练读入数据\n",
    "        for i, (images, labels) in enumerate(data_loader_train):\n",
    "            images = images.astype(ms.float32)\n",
    "            labels = labels.astype(ms.int32)\n",
    "            loss = train_step(images, labels)\n",
    "            losses.append(loss)\n",
    "\n",
    "        # 每个epoch结束后，验证准确率\n",
    "        matrix = model.eval(val_dataset)\n",
    "\n",
    "        epoch_end = time.time()\n",
    "        epoch_seconds = (epoch_end - epoch_start)\n",
    "        step_seconds = epoch_seconds / step_size_train\n",
    "\n",
    "        print(\"-\" * 20)\n",
    "        print(\"Epoch: [%3d/%3d], Average Train Loss: [%5.3f] | \"\n",
    "              \"Train pixel Acc: [%5.3f] | \"\n",
    "              \"Train IoU: [%5.3f] | \"\n",
    "              \"Train R: [%5.3f] | \"\n",
    "              \"Train P: [%5.3f] | \"\n",
    "              \"Val pixel Acc: [%5.3f] | \"\n",
    "              \"Val IoU: [%5.3f] | \" \n",
    "              \"Val R: [%5.3f] | \"\n",
    "              \"Val P: [%5.3f] \" % (\n",
    "            epoch + 1, EPOCHS, sum(losses) / len(losses), train_acc_tool.eval(), train_iou_tool.eval(),\n",
    "            train_recall_tool.eval(), train_precision_tool.eval(), matrix[\"pixel accuracy\"], matrix[\"IoU\"], matrix[\"recall\"], matrix[\"precision\"]\n",
    "        ))\n",
    "        print(\"epoch time: %.3f s, per step time: %.3f s\" % (\n",
    "            epoch_seconds, step_seconds\n",
    "        ))\n",
    "\n",
    "        summary_record.add_value('scalar', 'train_loss', ms.Tensor(sum(losses) / len(losses)))\n",
    "        summary_record.add_value('scalar', 'train_pixel_acc', ms.Tensor(train_acc_tool.eval()))\n",
    "        summary_record.add_value('scalar', 'train_iou', ms.Tensor(train_iou_tool.eval()))\n",
    "        summary_record.add_value('scalar', 'train_recall', ms.Tensor(train_recall_tool.eval()))\n",
    "        summary_record.add_value('scalar', 'train_precision', ms.Tensor(train_precision_tool.eval()))\n",
    "        \n",
    "        summary_record.add_value('scalar', 'val_pixel_acc', ms.Tensor(matrix[\"pixel accuracy\"]))\n",
    "        summary_record.add_value('scalar', 'val_iou', ms.Tensor(matrix[\"IoU\"]))\n",
    "        summary_record.add_value('scalar', 'val_recall', ms.Tensor(matrix[\"recall\"]))\n",
    "        summary_record.add_value('scalar', 'val_precision', ms.Tensor(matrix[\"precision\"]))\n",
    "        \n",
    "        summary_record.record(epoch)\n",
    "        \n",
    "        if matrix[\"IoU\"] > best_iou:\n",
    "            best_iou = matrix[\"IoU\"]\n",
    "            ms.save_checkpoint(network, os.path.join(best_ckpt_dir, \"BestDuckNet.ckpt\"))\n",
    "            print(\"*************************************************\")\n",
    "            print(\"The best IoU achieved so far is: [%5.3f], the weight has been saved\" % (matrix[\"IoU\"]))\n",
    "            print(\"*************************************************\")\n",
    "            matrix_test = model.eval(test_dataset)\n",
    "            print(\"Test Acc: [%5.3f] | Test IoU: [%5.3f] | Test R: [%5.3f] | Test P: [%5.3f]\" % (\n",
    "                matrix_test[\"pixel accuracy\"],\n",
    "                matrix_test[\"IoU\"],\n",
    "                matrix_test[\"recall\"],\n",
    "                matrix_test[\"precision\"]))\n",
    "            summary_record.add_value('scalar', 'test_pixel_acc', ms.Tensor(matrix_test[\"pixel accuracy\"]))\n",
    "            summary_record.add_value('scalar', 'tet_iou', ms.Tensor(matrix_test[\"IoU\"]))\n",
    "            summary_record.add_value('scalar', 'test_recall', ms.Tensor(matrix_test[\"recall\"]))\n",
    "            summary_record.add_value('scalar', 'test_precision', ms.Tensor(matrix_test[\"precision\"]))\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"End of validation the best mIoU is: {best_iou: 5.3f}\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MindSpore",
   "language": "python",
   "name": "mindspore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
